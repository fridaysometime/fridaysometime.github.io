(window.webpackJsonp=window.webpackJsonp||[]).push([[129],{322:function(e,t,s){"use strict";s.r(t);var r=s(0),a=Object(r.a)({},function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("div",{staticClass:"content"},[e._m(0),e._v(" "),e._m(1),e._v(" "),e._m(2),e._v(" "),s("p",[e._v("hadoop内部拆分成几个独立的模块，存储与计算功能独立：")]),e._v(" "),s("p",[e._v("HDFS为分布式文件系统，负责文件存储")]),e._v(" "),s("p",[e._v("MapReduce，MR，计算框架提供计算支持")]),e._v(" "),s("p",[e._v("YARN是资源调度模块，MR程序由yarn来调度运行，同时yarn还可以为其他系统提供调度服务，如spark")]),e._v(" "),e._m(3),e._v(" "),s("ol",[e._m(4),e._v(" "),e._m(5),e._v(" "),e._m(6),e._v(" "),s("li",[s("p",[e._v("文件从HDFS上下载到本地的命令。")]),e._v(" "),s("p",[e._v("get")]),e._v(" "),s("p",[e._v("使用方法：hadoop fs -get [-ignorecrc][-crc] "),s("src",[s("localdst")],1)],1),e._v(" "),s("p",[e._v("hadoop fs -get /user/hadoop/file localfile")]),e._v(" "),s("p",[e._v("hadoop fs -get hdfs://host:port/user/hadoop/file localfile")])]),e._v(" "),e._m(7),e._v(" "),e._m(8),e._v(" "),e._m(9),e._v(" "),e._m(10),e._v(" "),e._m(11),e._v(" "),e._m(12),e._v(" "),e._m(13)]),e._v(" "),e._m(14),e._v(" "),s("p",[e._v("Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。")]),e._v(" "),s("p",[e._v("区别：")]),e._v(" "),e._m(15),e._v(" "),s("p",[e._v("联系：在大数据架构中，Hive和HBase是协作关系，数据流一般如下")]),e._v(" "),e._m(16),e._v(" "),e._m(17),e._v(" "),s("p",[e._v("Spark: spark的核心是一种新型的大数据计算框架，可以基于Hadoop上存储的大数据进行计算（HDFS,hive ）Spark替代Hadoop的一部分，只是替代其计算框架，mapreduce,hive，但spark本身不提供大数据存储;")]),e._v(" "),e._m(18),e._v(" "),s("p",[e._v("spark的计算模型与MapReduce是完全不同的，spark是基于内存的一种计算框架,有时也会使用磁盘，spark shuffle也会使用磁盘，但是很多操作，比如说简单的map，没有reduce操作，或者是filter类的操作，都是可以直接基于内存进行计算的。")]),e._v(" "),s("p",[e._v("MapReduce的计算模型非常固定，而且死板，必须基于磁盘，以及大量的网络传输;")]),e._v(" "),s("p",[e._v("所以，spark的速度可以比MapReduce，hive底层也是基于MapReduce来执行SQL语句的，速度快速至少数倍，甚至十倍上百倍。")]),e._v(" "),e._m(19),e._v(" "),s("p",[e._v("spark有很多种模式，最简单就是单机本地模式，还有单机伪分布式模式，复杂的则运行在集群中，目前能很好的运行在 Yarn和 Mesos\n中，当然 Spark 还有自带的 Standalone 模式，对于大多数情况 Standalone 模式就足够了，如果企业已经有 Yarn 或者 Mesos\n环境，也是很方便部署的。")]),e._v(" "),e._m(20),e._v(" "),s("p",[e._v("​\t\tspark-submit --master spark://wl1:6066 --deploy-mode cluster")]),e._v(" "),s("p",[e._v("​\t\t客户端的SparkSubmit进程会在应用程序提交给集群之后就退出;")]),e._v(" "),s("p",[e._v("​\t\tMaster会在集群中选择一个Worker进程生成一个子进程DriverWrapper来启动driver程序;")]),e._v(" "),s("p",[e._v("​\t\t而该DriverWrapper 进程会占用Worker进程的一个core，所以同样的资源下配置下​会比第3种运行模式，少用1个core来参与计算(观察下图executor id 7的core数);应用程序的结果，会在执行driver程序的节点的stdout中输出，而不是打印在屏幕上;")]),e._v(" "),e._m(21),e._v(" "),e._m(22),e._v(" "),s("p",[e._v('df = sqlContext.createDataFrame([("a", 14, 13.0),("c", 14, 33.0),("d", 21, 23.0),("e", 21, 3.0)], ("cust", "x2", "x3"))\n请写出一条语句spark或hive语句，使用窗口函数按x2分组，找出每组中最小的记录\na=df.withColumn("rn", F.row_number().over(Window.partitionBy("x2").orderBy(F.asc("x3")))).filter("rn = 1").drop("rn")')]),e._v(" "),e._m(23),e._v(" "),s("p",[e._v("利用nohup写出一条命令将spark submit提交的test.py的日志写入指定的路径（/home/test/result.log）\nnohup spark-submit test.py 1>/home/test/result.log &")]),e._v(" "),s("p",[e._v("nohup sh promo_elasity_submit.sh promo_elasticity_calculate_spark.py 2017-12-31 2017-01-01 insert 1>/home/test/result.log &")]),e._v(" "),e._m(24),e._v(" "),s("p",[e._v("简述hive的row_number()、percent_rank()，rank()和dense_rank()的区别以及具体使用场景；并为下面的场景写一段符合要求的hivesql\n学生表student：包括字段age（年龄）,gender（性别）,no(学号)，总共10条记录，分别查找男女中年龄由大到小排名前3的人（排名不连续，人数可能大于3）")]),e._v(" "),s("p",[e._v("row_number:不管排名是否有相同的，都按照顺序1，2，3…..n\nrank:排名相同的名次一样，同一排名有几个，后面排名就会跳过几次\ndense_rank:排名相同的名次一样，且后面名次不跳跃\npercent_rank() 返回相对百分比排名")]),e._v(" "),s("p",[e._v("select gender,age, rank() over (partition by gender order by age desc) as ranks from student having ranks<=3")]),e._v(" "),e._m(25),e._v(" "),s("p",[e._v('df = sqlContext.createDataFrame([("a", 14, 1),("c", 64, 2),("d", 102, 3),("e", 20, 4)], ("cust", "percentage", "type"))\ndf为dataframe中包含percentage和type这2个字段，且percentage字段范围应该在[0,100]之间，type在[1,2,3]中取，\n写出判断字段的数据范围是否符合要求的语句：\ndf.filter(~df.type.isin(1,2,3)).show()\ndf.agg({\'percentage\':\'max\'}).collect()[0][0]\ndf.agg({\'percentage\':\'min\'}).collect()[0][0]\n答案不唯一，窗口函数也可。')]),e._v(" "),e._m(26),e._v(" "),s("p",[e._v("简述spark的运行模式")]),e._v(" "),s("p",[e._v("Spark 有很多种模式，最简单就是单机本地模式，还有单机伪分布式模式，复杂的则运行在集群中，目前能很好的运行在 Yarn和 Mesos 中，当然 Spark 还有自带的 Standalone 模式，对于大多数情况 Standalone 模式就足够了，如果企业已经有 Yarn 或者 Mesos 环境，也是很方便部署的。\nlocal(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程; standalone(集群模式)：典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HA\non yarn(集群模式)： 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算\non mesos(集群模式)： 运行在 mesos 资源管理器框架之上，由 mesos 负责资源管理，Spark 负责任务调度和计算\non cloud(集群模式)：比如 AWS 的 EC2，使用这个模式能很方便的访问 Amazon的 S3;Spark 支持多种分布式存储系统：HDFS 和 S3")]),e._v(" "),e._m(27),e._v(" "),s("p",[e._v("写出常见的hdfs命令：")]),e._v(" "),s("p",[e._v("在根目录创建文件夹hadoop fs -mkdir xulin\n删除在根目录的空文件夹：hdfs dfs -rm -r \\xulintest\n查看对应目录下的文件：比如查看某个数据库下某个表的文件或查看目录结构\nhdfs dfs -ls hdfs://ns15/user/mart_cis/dev.db/dev_op_pop_sku_elasticity_da\nhdfs dfs -ls  hdfs://ns11/user/mart_rmb/sunzeye/raw_data/elasticity\n查看dev_op_pop_sku_elasticity_da表里有多少个分区文件\n从hdfs下上下载文件到本地\nhadoop fs -get /user/hadoop/file localfile\n查看hdfs上某文件\nhadoop dfs -cat hdfs://ns11/user/rmb_test_account/test_xl/preprocessed_data/elasticity/part-00000")]),e._v(" "),e._m(28),e._v(" "),s("p",[e._v("spark中cache(),persist(),checkpoint()分别是什么作用，有什么区别？")]),e._v(" "),s("p",[e._v("cache()：会被重复使用的(但是)不能太大的RDD需要cache。cache 只使用 memory，不适用磁盘cache 机制是每计算出一个要 cache 的 partition 就直接将其 cache 到内存了。\ncheckpoint() ：写磁盘的话那就叫 checkpoint了。没有使用这种第一次计算得到就存储的方法，而是等到 job 结束后另外启动专门的 job 去完成。checkpoint 将 RDD 持久化到 HDFS 或本地文件夹，如果不被手动 remove 掉，是一直存在的。\npersist():将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被 cache 到磁盘上的 RDD 也会被清空。")])])},[function(){var e=this.$createElement,t=this._self._c||e;return t("div",{staticClass:"tip custom-block"},[t("p",{staticClass:"custom-block-title"},[this._v("TIP")]),this._v(" "),t("p",[this._v("做项目的时候了解一下大数据的相关知识，只恨我们技术浅薄，能学以致用的点太少，大数据的知识又多又深，我们所了解的也只是皮毛，应用在项目中的也都是基础的东西；如果保证数据的质量，如何提高数据类产品质量的测试效率，如何测试算法，我们探究了一年多，然而效果却很单薄")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("h1",{attrs:{id:"大数据基础"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据基础","aria-hidden":"true"}},[this._v("#")]),this._v(" 大数据基础")])},function(){var e=this.$createElement,t=this._self._c||e;return t("h2",{attrs:{id:"hadoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop","aria-hidden":"true"}},[this._v("#")]),this._v(" Hadoop")])},function(){var e=this.$createElement,t=this._self._c||e;return t("h3",{attrs:{id:"hdfs基本命令"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs基本命令","aria-hidden":"true"}},[this._v("#")]),this._v(" HDFS基本命令")])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("根目录：hdfs dfs -ls,")]),this._v(" "),t("p",[this._v("hdfs dfs -ls  /")]),this._v(" "),t("p",[this._v("显示所有：hdfs dfs -ls -R,太多了一般不要直接用，用grep过滤")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("删除在根目录的空文件夹：hdfs dfs -rm -r \\xulintest")]),this._v(" "),t("p",[this._v("根目录的路径：hdfs://ns15/user/mart_cis/xulin")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("查看对应目录下的文件：比如查看某个表的文件")]),this._v(" "),t("p",[this._v("hdfs dfs -ls hdfs://ns15/user/mart_cis/dev.db/dev_op_pop_sku_elasticity_da")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("多级目录-需要一级一级的创建\n首先到hdfs的用户-然后创建\nsu hdfs")]),this._v(" "),t("pre",[t("code",[this._v("hdfs dfs -mkdir /Test\nhdfs dfs -mkdir /Test/first\nhdfs dfs -mkdir /Test/first/data\nhdfs dfs -mkdir /Test/first/data/ok\n")])])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("删除目录首先查看当前用户，再查看准备删除的目录的文件之后--删除，以确保没有误操作\nrf参数表示递归强制删除-尽量不用强制删除\nrm命令删除指定的文件，只删除 非空目录 和 文件\n删除空目录 - r 指示rm将参数中列出的全部目录和子目录均递归地删除\nhdfs  dfsadmin -report\nhdfs dfs -ls  /test/\nhdfs dfs -ls  /test/happy\nhdfs dfs -rm  -r -f /test/happy")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("报告HDFS的基本统计信息")]),this._v(" "),t("p",[this._v("hdfs dfsadmin -report")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("统计多个文件行数")]),this._v(" "),t("p",[this._v("hdfs dfs -cat  /test/first_data_ok_20129* | wc -l")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("统计文件大小")]),this._v(" "),t("p",[this._v("hdfs dfs -count /test/first_data_ok_20129")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("查看文件的前几行--具体到文件\nhdfs dfs -tail /test/first_data_ok_2012.json")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("li",[t("p",[this._v("查看部分文件\nhdfs dfs -ls  /Test/tmp/first_data_ok_20151203*")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("h2",{attrs:{id:"hive-hbase"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive-hbase","aria-hidden":"true"}},[this._v("#")]),this._v(" hive & HBASE")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",[t("li",[this._v("Hbase：Hadoop database的简称，也就是基于Hadoop数据库，是一种NoSQL数据库，主要适用于海量明细数据（十亿、百亿）的随机实时查询，如日志明细、交易清单、轨迹行为等；")]),this._v(" "),t("li",[this._v("Hive：Hive是Hadoop数据仓库，严格来说，不是数据库，主要是让开发人员能够通过SQL来计算和处理HDFS上的结构化数据，适用于离线的批量数据计算。\n"),t("ul",[t("li",[this._v("通过元数据来描述Hdfs上的结构化文本数据，通俗点来说，就是定义一张表来描述HDFS上的结构化文本，包括各列数据名称，数据类型是什么等，方便我们处理数据，当前很多SQL      ON Hadoop的计算引擎均用的是hive的元数据，如Spark SQL、Impala等；")]),this._v(" "),t("li",[this._v("基于第一点，通过SQL来处理和计算HDFS的数据，Hive会将SQL翻译为Mapreduce来处理数据；")])])])])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",[t("li",[this._v("通过ETL工具将数据源抽取到HDFS存储；")]),this._v(" "),t("li",[this._v("通过Hive清洗、处理和计算原始数据；")]),this._v(" "),t("li",[this._v("HIve清洗处理后的结果，如果是面向海量数据随机查询场景的可存入Hbase；")]),this._v(" "),t("li",[this._v("数据应用从HBase查询数据；")])])},function(){var e=this.$createElement,t=this._self._c||e;return t("h1",{attrs:{id:"spark"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark","aria-hidden":"true"}},[this._v("#")]),this._v(" spark")])},function(){var e=this.$createElement,t=this._self._c||e;return t("p",[t("strong",[this._v("spark 和 mr")]),this._v(":")])},function(){var e=this.$createElement,t=this._self._c||e;return t("p",[t("strong",[this._v("spark运行模式")]),this._v("：")])},function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ul",[s("li",[s("p",[e._v("local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程;")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("本地：该模式被称为Local[N]模式，是用单机的多个线程来模拟Spark分布式计算，通常用来验证开发出来的应用程序逻辑上有没有问题。其中N代表可以使用N个线程，每个线程拥有一个core。如果不指定N，则默认是1个线程（该线程有1个core）。")]),e._v(" "),s("p",[e._v("如果是local[*]，则代表 Run Spark locally with as many worker threads as logical cores on your machine.")]),e._v(" "),s("p",[e._v("如下：")]),e._v(" "),s("p",[e._v("spark-submit 和 spark-submit --master local 效果是一样的")]),e._v(" "),s("p",[e._v("（同理：spark-shell 和 spark-shell --master local 效果是一样的）")]),e._v(" "),s("p",[e._v("spark-submit --master local[4] 代表会有4个线程（每个线程一个core）来并发执行应用程序。")])]),e._v(" "),s("li",[s("p",[e._v("本地伪集群：这种运行模式，和Local[N]很像，不同的是，它会在单机启动多个进程来模拟集群下的分布式场景，而不像Local[N]这种多个线程只能在一个进程下委屈求全的共享资源。通常也是用来验证开发出来的应用程序逻辑上有没有问题，或者想使用Spark的计算框架而没有太多资源。")]),e._v(" "),s("p",[e._v("用法是：提交应用程序时使用local-cluster[x,y,z]参数：x代表要生成的executor数，y和z分别代表每个executor所拥有的core和memory数。")]),e._v(" "),s("p",[s("code",[e._v("spark-submit --master local-cluster[2, 3, 1024]")])]),e._v(" "),s("p",[e._v("（同理：spark-shell --master local-cluster[2, 3, 1024]用法也是一样的）")]),e._v(" "),s("p",[e._v("上面这条命令代表会使用2个executor进程，每个进程分配3个core和1G的内存，来运行应用程序。")]),e._v(" "),s("p",[e._v("SparkSubmit依然充当全能角色，又是Client进程，又是driver程序，还有点资源管理的作用。生成的两个CoarseGrainedExecutorBackend，就是用来并发执行程序的进程。")]),e._v(" "),s("p",[e._v("运行该模式依然非常简单，只需要把Spark的安装包解压后，改一些常用的配置即可使用。而不用启动Spark的Master、Worker守护进程( 只有集群的standalone方式时，才需要这两个角色)，也不用启动Hadoop的各服务（除非你要用到HDFS），这是和其他模式的区别哦，要记住才能理解。")])])])]),e._v(" "),s("li",[s("p",[e._v("standalone(集群模式)：典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现HA; Spark standalone模式下，集群资源调度由master节点复制。standalone模式只支持简单的资源分配策略，每个人物固定数量的core，各job按顺序依次分配资源，资源不够时排队等待。")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("standalone-client:")]),e._v(" "),s("p",[e._v("和单机运行的模式不同，这里必须在执行应用程序前，先启动Spark的Master和Worker守护进程。不用启动Hadoop服务，除非你用到了HDFS的内容。")]),e._v(" "),s("p",[s("code",[e._v("start-master.sh")])]),e._v(" "),s("p",[s("code",[e._v("start-slave.sh -h hostname url:master")])]),e._v(" "),s("p",[e._v("图省事，可以在想要做为Master的节点上用start-all.sh一条命令即可，不过这样做，和上面的分开配置有点差别，以后讲到数据本地性如何验证时会说。")]),e._v(" "),s("p",[e._v("这种运行模式，可以使用Spark的8080 web ui来观察资源和应用程序的执行情况了。")]),e._v(" "),s("p",[e._v("言归正传，用如下命令提交应用程序")]),e._v(" "),s("p",[e._v("spark-submit --master spark://wl1:7077")]),e._v(" "),s("p",[e._v("或者 spark-submit --master spark://wl1:7077 --deploy-mode client")]),e._v(" "),s("p",[e._v("代表着会在所有有Worker进程的节点上启动Executor来执行应用程序，此时产生的JVM进程如下：（非master节点，除了没有Master、SparkSubmit，其他进程都一样）")]),e._v(" "),s("p",[e._v("Master进程做为cluster manager，用来对应用程序申请的资源进行管理；")]),e._v(" "),s("p",[e._v("SparkSubmit 做为Client端和运行driver程序；")]),e._v(" "),s("p",[e._v("CoarseGrainedExecutorBackend 用来并发执行应用程序；")]),e._v(" "),s("p",[e._v("注意，Worker进程生成几个Executor，每个Executor使用几个core，这些都可以在spark-env.sh里面配置，此处不在啰嗦。")])]),e._v(" "),s("li",[s("p",[e._v("standalone-cluster:")]),e._v(" "),s("p",[e._v("使用如下命令执行应用程序（前提是已经启动了spark的Master、Worker守护进程）不用启动Hadoop服务，除非你用到了HDFS的内容。")])])])])])},function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ul",[s("li",[s("p",[e._v("on yarn(集群模式)：运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算;")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("on client:")]),e._v(" "),s("p",[e._v("现在越来越多的场景，都是Spark跑在Hadoop集群中，所以为了做到资源能够均衡调度，会使用YARN来做为Spark的Cluster Manager，来为Spark的应用程序分配资源。")]),e._v(" "),s("p",[e._v("在执行Spark应用程序前，要启动Hadoop的各种服务。由于已经有了资源管理器，所以不需要启动Spark的Master、Worker守护进程。相关配置的修改，请自行研究。")]),e._v(" "),s("p",[e._v("使用如下命令执行应用程序")]),e._v(" "),s("p",[e._v("spark-submit --master yarn")]),e._v(" "),s("p",[e._v("或者 spark-submit --master yarn --deploy-mode client")]),e._v(" "),s("p",[e._v("提交应用程序后，各节点会启动相关的JVM进程，如下：")]),e._v(" "),s("p",[e._v("在Resource Manager节点上提交应用程序，会生成SparkSubmit进程，该进程会执行driver程序。")])]),e._v(" "),s("li",[s("p",[e._v("on cluster:")]),e._v(" "),s("p",[e._v("使用如下命令执行应用程序:")]),e._v(" "),s("p",[e._v("spark-submit --master yarn --deploy-mode cluster")]),e._v(" "),s("p",[e._v("和第5种运行模式，区别如下：")]),e._v(" "),s("p",[e._v("在Resource Manager端提交应用程序，会生成SparkSubmit进程，该进程只用来做Client端，应用程序提交给集群后，就会删除该进程。")]),e._v(" "),s("p",[e._v("Resource Manager在集群中的某个NodeManager上运行ApplicationMaster，该AM同时会执行driver程序。紧接着，会在各NodeManager上运行CoarseGrainedExecutorBackend来并发执行应用程序。")])])])]),e._v(" "),s("li",[s("p",[e._v("on mesos(集群模式)：运行在 mesos 资源管理器框架之上，由 mesos 负责资源管理，Spark 负责任务调度和计算;")])]),e._v(" "),s("li",[s("p",[e._v("on      cloud(集群模式)：比如 AWS 的 EC2，使用这个模式能很方便的访问 Amazon的 S3;Spark 支持多种分布式存储系统：HDFS 和 S3;")])])])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"2"}},[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"3"}},[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"4"}},[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"5"}},[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"6"}},[t("li")])},function(){var e=this.$createElement,t=this._self._c||e;return t("ol",{attrs:{start:"7"}},[t("li")])}],!1,null,null,null);t.default=a.exports}}]);